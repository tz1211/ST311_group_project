{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv \n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd \n",
    "from dotenv import load_dotenv\n",
    "from RAG.rag_agent import RAGAgent \n",
    "from RAG.rag_searcher import RAGSearcher\n",
    "from utils.clients import create_chat_client, create_embed_client \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(dotenv_path='../.env', override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  \n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('../logs/rag_agent.log')  # Remove StreamHandler to prevent console output\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benchmark = pd.read_csv(\"../data/longbench_filtered.csv\", delimiter=\"§\", engine=\"python\")\n",
    "df_context_asc = pd.read_csv(\"../data/longbench_context_chunked_asc.csv\", delimiter=\"§\", engine=\"python\")\n",
    "df_context_simple = pd.read_csv(\"../data/longbench_context_chunked_simple.csv\", delimiter=\"§\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1889d785e1d1408fbb2e7b01991cb68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_client = create_chat_client()\n",
    "embed_client = create_embed_client()\n",
    "\n",
    "rag_agent = RAGAgent(\n",
    "    chat_client=chat_client,\n",
    "    embed_client=embed_client,\n",
    "    chat_model=os.getenv(\"MODEL_NAME\"),\n",
    "    searcher=RAGSearcher(),\n",
    "    max_tokens=130000,\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                                               66f36490821e116aacb2cc22\n",
       "domain                                                  Single-Document QA\n",
       "sub_domain                                                       Financial\n",
       "difficulty                                                            easy\n",
       "length                                                               short\n",
       "question                 According to the report, how to promote the co...\n",
       "choice_A                 Through technology empowerment, change the way...\n",
       "choice_B                 Establish new types of courts, such as intelle...\n",
       "choice_C                 Improve the work ability of office staff and s...\n",
       "choice_D                 Use advanced information systems to improve th...\n",
       "answer                                                                   D\n",
       "context                  Contents\\nPreface.\\n.............................\n",
       "context_tokens                                                       38133\n",
       "within_context_window                                                 True\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benchmark.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "n = random.randint(0, len(df_benchmark))\n",
    "\n",
    "id = df_benchmark.iloc[n][\"_id\"]\n",
    "question = df_benchmark.iloc[n][\"question\"]\n",
    "choice_a = df_benchmark.iloc[n][\"choice_A\"]\n",
    "choice_b = df_benchmark.iloc[n][\"choice_B\"]\n",
    "choice_c = df_benchmark.iloc[n][\"choice_C\"]\n",
    "choice_d = df_benchmark.iloc[n][\"choice_D\"]\n",
    "correct_answer = df_benchmark.iloc[n][\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24792</th>\n",
       "      <td>671b13f5bb02136c067d4ee3</td>\n",
       "      <td>0</td>\n",
       "      <td>{ \" meta \" : { \" name _ exp \" : \" qwen2 - 72b ...</td>\n",
       "      <td>[[-0.045745849609375, 0.0269775390625, -0.0158...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24793</th>\n",
       "      <td>671b13f5bb02136c067d4ee3</td>\n",
       "      <td>1</td>\n",
       "      <td>8, 7 ], \" mean \" : 8. 7, \" mean _ ratio \" : 5....</td>\n",
       "      <td>[[-0.01136016845703125, 0.03326416015625, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24794</th>\n",
       "      <td>671b13f5bb02136c067d4ee3</td>\n",
       "      <td>2</td>\n",
       "      <td>responses \" : [ 2, 2, 2, 2, 2, 2, 2, 2, 2, 2 ]...</td>\n",
       "      <td>[[-0.0289459228515625, 0.0205230712890625, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24795</th>\n",
       "      <td>671b13f5bb02136c067d4ee3</td>\n",
       "      <td>3</td>\n",
       "      <td>2, \" winner _ num \" : 10 }, { \" responses \" : ...</td>\n",
       "      <td>[[-0.0155487060546875, 0.0155792236328125, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24796</th>\n",
       "      <td>671b13f5bb02136c067d4ee3</td>\n",
       "      <td>4</td>\n",
       "      <td>\" }, { \" role \" : \" user \", \" content \" : \" un...</td>\n",
       "      <td>[[0.0008091926574707031, -0.005794525146484375...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24848</th>\n",
       "      <td>671b13f5bb02136c067d4ee3</td>\n",
       "      <td>56</td>\n",
       "      <td>round 4 : \\ n \\ naverage number chosen : 15. 5...</td>\n",
       "      <td>[[-0.0005040168762207031, 0.0042724609375, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24849</th>\n",
       "      <td>671b13f5bb02136c067d4ee3</td>\n",
       "      <td>57</td>\n",
       "      <td>: \" congratulation you won. \" }, { \" role \" : ...</td>\n",
       "      <td>[[-0.0101318359375, -0.01042938232421875, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24850</th>\n",
       "      <td>671b13f5bb02136c067d4ee3</td>\n",
       "      <td>58</td>\n",
       "      <td>_ number \\ \" : \\ \" 2 \\ \" } \" }, { \" role \" : \"...</td>\n",
       "      <td>[[-0.0128936767578125, -0.00884246826171875, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24851</th>\n",
       "      <td>671b13f5bb02136c067d4ee3</td>\n",
       "      <td>59</td>\n",
       "      <td>\\ nyou chose : \" }, { \" role \" : \" assistant \"...</td>\n",
       "      <td>[[0.0120849609375, 0.00799560546875, -0.076354...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24852</th>\n",
       "      <td>671b13f5bb02136c067d4ee3</td>\n",
       "      <td>60</td>\n",
       "      <td>##arget number ( 2 / 3 of average ) : 1. 33 \\ ...</td>\n",
       "      <td>[[-0.01267242431640625, 0.0259857177734375, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            _id  chunk_id  \\\n",
       "24792  671b13f5bb02136c067d4ee3         0   \n",
       "24793  671b13f5bb02136c067d4ee3         1   \n",
       "24794  671b13f5bb02136c067d4ee3         2   \n",
       "24795  671b13f5bb02136c067d4ee3         3   \n",
       "24796  671b13f5bb02136c067d4ee3         4   \n",
       "...                         ...       ...   \n",
       "24848  671b13f5bb02136c067d4ee3        56   \n",
       "24849  671b13f5bb02136c067d4ee3        57   \n",
       "24850  671b13f5bb02136c067d4ee3        58   \n",
       "24851  671b13f5bb02136c067d4ee3        59   \n",
       "24852  671b13f5bb02136c067d4ee3        60   \n",
       "\n",
       "                                              chunk_text  \\\n",
       "24792  { \" meta \" : { \" name _ exp \" : \" qwen2 - 72b ...   \n",
       "24793  8, 7 ], \" mean \" : 8. 7, \" mean _ ratio \" : 5....   \n",
       "24794  responses \" : [ 2, 2, 2, 2, 2, 2, 2, 2, 2, 2 ]...   \n",
       "24795  2, \" winner _ num \" : 10 }, { \" responses \" : ...   \n",
       "24796  \" }, { \" role \" : \" user \", \" content \" : \" un...   \n",
       "...                                                  ...   \n",
       "24848  round 4 : \\ n \\ naverage number chosen : 15. 5...   \n",
       "24849  : \" congratulation you won. \" }, { \" role \" : ...   \n",
       "24850  _ number \\ \" : \\ \" 2 \\ \" } \" }, { \" role \" : \"...   \n",
       "24851  \\ nyou chose : \" }, { \" role \" : \" assistant \"...   \n",
       "24852  ##arget number ( 2 / 3 of average ) : 1. 33 \\ ...   \n",
       "\n",
       "                                              embeddings  \n",
       "24792  [[-0.045745849609375, 0.0269775390625, -0.0158...  \n",
       "24793  [[-0.01136016845703125, 0.03326416015625, -0.0...  \n",
       "24794  [[-0.0289459228515625, 0.0205230712890625, -0....  \n",
       "24795  [[-0.0155487060546875, 0.0155792236328125, -0....  \n",
       "24796  [[0.0008091926574707031, -0.005794525146484375...  \n",
       "...                                                  ...  \n",
       "24848  [[-0.0005040168762207031, 0.0042724609375, -0....  \n",
       "24849  [[-0.0101318359375, -0.01042938232421875, -0.0...  \n",
       "24850  [[-0.0128936767578125, -0.00884246826171875, -...  \n",
       "24851  [[0.0120849609375, 0.00799560546875, -0.076354...  \n",
       "24852  [[-0.01267242431640625, 0.0259857177734375, -0...  \n",
       "\n",
       "[61 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_context_simple[df_context_simple[\"_id\"] == id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which following player won the least times in the game?\n",
      "A: player_1\n",
      "B: player_3\n",
      "C: player_5\n",
      "D: player_8\n"
     ]
    }
   ],
   "source": [
    "def format_question(question: str, choice_a: str, choice_b: str, choice_c: str, choice_d: str) -> str:\n",
    "    return f\"Question: {question}\\nA: {choice_a}\\nB: {choice_b}\\nC: {choice_c}\\nD: {choice_d}\"\n",
    "\n",
    "formatted_question = format_question(question, choice_a, choice_b, choice_c, choice_d)\n",
    "print(formatted_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/lp/6tqfnwxx7ks38f2yd_pqft0c0000gn/T/ipykernel_72060/2235900583.py\", line 1, in <module>\n",
      "    llm_answer = rag_agent.generate_response(formatted_question, df_context_simple, id, top=3)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/Documents/GitHub/ST311_group_project/notebooks/../RAG/rag_agent.py\", line 51, in generate_response\n",
      "    chat_completion_response = self.chat_client.chat.completions.create(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 929, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/openai/_base_client.py\", line 1276, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/openai/_base_client.py\", line 949, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/openai/_base_client.py\", line 1057, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': 'You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2176, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1182, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1053, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 861, in structured_traceback\n",
      "    formatted_exceptions: list[list[str]] = self.format_exception_as_a_whole(\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 773, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 652, in format_record\n",
      "    frame_info.lines,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/IPython/core/tbtools.py\", line 355, in lines\n",
      "    return self._sd.lines  # type: ignore[misc]\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/stack_data/core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/stack_data/core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/stack_data/core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "                      ^^^^^^^^^^^^\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "source": [
    "llm_answer = rag_agent.generate_response(formatted_question, df_context_simple, id, top=3)\n",
    "print(llm_answer)\n",
    "print(f\"LLM answer == Correct answer: {llm_answer == correct_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_question(row, context_df, rag_agent):\n",
    "    # 提取问题和正确答案\n",
    "    question = row[\"question\"]\n",
    "    correct_answer = row[\"answer\"]\n",
    "    \n",
    "    # 格式化问题\n",
    "    formatted_question = format_question(\n",
    "        question, row[\"choice_A\"], row[\"choice_B\"], row[\"choice_C\"], row[\"choice_D\"]\n",
    "    )\n",
    "    \n",
    "    # 生成LLM的回答\n",
    "    llm_answer = rag_agent.generate_response(formatted_question, context_df, row[\"_id\"], top=3)\n",
    "    \n",
    "    # 比较LLM的回答与正确答案\n",
    "    is_correct = llm_answer == correct_answer\n",
    "    return is_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(df_benchmark, context_dfs, rag_agent):\n",
    "    results = []\n",
    "    for index, row in tqdm(df_benchmark.iterrows(), total=df_benchmark.shape[0], desc=\"Benchmarking Progress\"):\n",
    "        # 根据需要选择不同的上下文数据集\n",
    "        context_df = context_dfs[\"simple\"]  # 这里可以根据需要选择不同的上下文方法\n",
    "        \n",
    "        # 进行基准测试\n",
    "        is_correct = benchmark_question(row, context_df, rag_agent)\n",
    "        results.append(is_correct)\n",
    "    \n",
    "    # 计算准确率\n",
    "    accuracy = sum(results) / len(results)\n",
    "    print(f\"Benchmarking accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Benchmarking Progress:   0%|          | 0/303 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/lp/6tqfnwxx7ks38f2yd_pqft0c0000gn/T/ipykernel_72060/2978949160.py\", line 9, in <module>\n",
      "    run_benchmark(df_benchmark, context_dfs, rag_agent)\n",
      "  File \"/var/folders/lp/6tqfnwxx7ks38f2yd_pqft0c0000gn/T/ipykernel_72060/3692385663.py\", line 8, in run_benchmark\n",
      "    is_correct = benchmark_question(row, context_df, rag_agent)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/lp/6tqfnwxx7ks38f2yd_pqft0c0000gn/T/ipykernel_72060/2891473983.py\", line 12, in benchmark_question\n",
      "    llm_answer = rag_agent.generate_response(formatted_question, context_df, row[\"_id\"], top=3)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/Documents/GitHub/ST311_group_project/notebooks/../RAG/rag_agent.py\", line 51, in generate_response\n",
      "    chat_completion_response = self.chat_client.chat.completions.create(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 929, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/openai/_base_client.py\", line 1276, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/openai/_base_client.py\", line 949, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/openai/_base_client.py\", line 1057, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.APIStatusError: Error code: 402 - {'error': 'You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.'}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2176, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1182, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1053, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 861, in structured_traceback\n",
      "    formatted_exceptions: list[list[str]] = self.format_exception_as_a_whole(\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 773, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 652, in format_record\n",
      "    frame_info.lines,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/IPython/core/tbtools.py\", line 355, in lines\n",
      "    return self._sd.lines  # type: ignore[misc]\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/stack_data/core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/stack_data/core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/spark/opt/anaconda3/envs/st311/lib/python3.11/site-packages/stack_data/core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "                      ^^^^^^^^^^^^\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "df_benchmark = pd.read_csv(\"../data/longbench_filtered.csv\", delimiter=\"§\", engine=\"python\")\n",
    "context_dfs = {\n",
    "    \"simple\": df_context_simple,\n",
    "    \"adaptive-semantic\": df_context_asc,  \n",
    "}\n",
    "\n",
    "# 运行基准测试\n",
    "run_benchmark(df_benchmark, context_dfs, rag_agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
