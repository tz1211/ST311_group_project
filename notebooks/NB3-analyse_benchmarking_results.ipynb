import pandas as pd

# Adjust the path as necessary
df = pd.read_csv("data/longbench_results.csv")
df.head()

# overall accuracy by method
df.groupby("method")["accuracy"].mean().sort_values(ascending=False)

# Define RAG methods
rag_methods = ["simple", "sentence", "adaptive-semantic"]

# Average tokens used
long_context_tokens = df[df["method"] == "long-context"]["tokens"].mean()
rag_tokens = df[df["method"].isin(rag_methods)]["tokens"].mean()

# Difference
long_context_tokens, rag_tokens, long_context_tokens - rag_tokens

df.groupby(["method", "domain"])["accuracy"].mean().unstack()
df.groupby(["method", "difficulty"])["accuracy"].mean().unstack()
df.groupby(["method", "length"])["accuracy"].mean().unstack()

# Other insights
import matplotlib.pyplot as plt
# Accuracy vs Token Usage Trade-off
df.groupby("method")[["accuracy", "tokens"]].mean().plot(kind="bar", secondary_y="tokens", figsize=(10,6), title="Accuracy vs Tokens Used")
plt.show()
# Correlation Analysis
# Examine if token usage correlates with accuracy
df[["tokens", "accuracy"]].corr()

