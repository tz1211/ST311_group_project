{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d378281c79134a07959c71d51b59d0e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import csv \n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd \n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from RAG.rag_agent import RAGAgent \n",
    "from RAG.rag_searcher import RAGSearcher\n",
    "from utils.clients import create_chat_client, create_embed_client \n",
    "\n",
    "tqdm.pandas()\n",
    "load_dotenv(override=True)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  \n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('../logs/rag_agent.log')  # Remove StreamHandler to prevent console output\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)  \n",
    "\n",
    "# Mute openai_messages_token_helper logger\n",
    "openai_token_logger = logging.getLogger(\"openai_messages_token_helper\")\n",
    "openai_token_logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benchmark = pd.read_csv(\"../data/longbench_filtered.csv\", delimiter=\"§\", engine=\"python\")\n",
    "df_context_asc = pd.read_csv(\"../data/longbench_context_chunked_asc.csv\", delimiter=\"§\", engine=\"python\")\n",
    "df_context_simple = pd.read_csv(\"../data/longbench_context_chunked_simple.csv\", delimiter=\"§\", engine=\"python\")\n",
    "df_context_sentence = pd.read_csv(\"../data/longbench_context_chunked_sentence.csv\", delimiter=\"§\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ab748f755242c3a00cea445bc5abdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_client = create_chat_client()\n",
    "embed_client = create_embed_client()\n",
    "\n",
    "rag_agent = RAGAgent(\n",
    "    chat_client=chat_client,\n",
    "    embed_client=embed_client,\n",
    "    chat_model=os.getenv(\"MODEL_NAME\"),\n",
    "    searcher=RAGSearcher(),\n",
    "    max_tokens=130000,\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_question(question: str, choice_a: str, choice_b: str, choice_c: str, choice_d: str) -> str:\n",
    "    return f\"Question: {question}\\nA: {choice_a}\\nB: {choice_b}\\nC: {choice_c}\\nD: {choice_d}\"\n",
    "\n",
    "\n",
    "def benchmark_question(row, df_context=None, top=5, mode=\"rag\"):\n",
    "    if mode not in [\"rag\", \"lc\"]:\n",
    "        raise ValueError(\"Invalid mode. Must be either 'rag' or 'lc'.\")\n",
    "\n",
    "    # Extract question and choices from row \n",
    "    id = row[\"_id\"]\n",
    "    question = row[\"question\"]\n",
    "    choice_a = row[\"choice_A\"]\n",
    "    choice_b = row[\"choice_B\"]\n",
    "    choice_c = row[\"choice_C\"]\n",
    "    choice_d = row[\"choice_D\"]\n",
    "    if mode == \"lc\": \n",
    "        context = row[\"context\"]\n",
    "    \n",
    "    # Format question into the format required by the RAG agent\n",
    "    formatted_question = format_question(question, choice_a, choice_b, choice_c, choice_d)\n",
    "\n",
    "    # Generate response from RAG agent\n",
    "    if mode == \"rag\": \n",
    "        llm_answer, token_count = rag_agent.generate_response_rag(formatted_question, df_context, id, top=top)\n",
    "    else: \n",
    "        llm_answer, token_count = rag_agent.generate_response_lc(formatted_question, context)\n",
    "    \n",
    "    return llm_answer, token_count\n",
    "\n",
    "\n",
    "def generate_benchmarking_results(df_benchmark, suffix, df_context=None, long_context=False):\n",
    "    \"\"\"Generate benchmarking results by running RAG agent predictions on benchmark questions.\n",
    "    \n",
    "    Args:\n",
    "        df_benchmark (pd.DataFrame): DataFrame containing benchmark questions and answer choices\n",
    "        df_context (pd.DataFrame): DataFrame containing context documents for RAG search\n",
    "        suffix (str): Suffix to append to the llm_answer column name in results. Takes value [\"simple\", \"asc\", \"sentence\", \"lc\"]\n",
    "        long_context (bool): Whether to use long context. Takes value [True, False]\n",
    "        \n",
    "    Returns:\n",
    "        None. Modifies df_benchmark in place by adding llm_answer_{suffix} column with predictions\n",
    "    \"\"\"\n",
    "    if not long_context:\n",
    "        results = df_benchmark.progress_apply(lambda row: benchmark_question(row, df_context, top=5, mode=\"rag\"), axis=1)\n",
    "    else: \n",
    "        results = df_benchmark.progress_apply(lambda row: benchmark_question(row, mode=\"lc\"), axis=1)\n",
    "\n",
    "    df_benchmark[f\"llm_answer_{suffix}\"], df_benchmark[f\"input_tokens_{suffix}\"] = zip(*results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4566f72ab78a4992a6a1a31c41ce9ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768f3c14fdbd459fafaa16994f36c335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test = df_benchmark.iloc[:5]\n",
    "generate_benchmarking_results(df_test, \"simple\", df_context_simple, long_context=False)\n",
    "generate_benchmarking_results(df_test, \"lc\", long_context=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>domain</th>\n",
       "      <th>sub_domain</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>length</th>\n",
       "      <th>question</th>\n",
       "      <th>choice_A</th>\n",
       "      <th>choice_B</th>\n",
       "      <th>choice_C</th>\n",
       "      <th>choice_D</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>context_tokens</th>\n",
       "      <th>within_context_window</th>\n",
       "      <th>llm_answer_simple</th>\n",
       "      <th>input_tokens_simple</th>\n",
       "      <th>llm_answer_lc</th>\n",
       "      <th>input_tokens_lc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66f36490821e116aacb2cc22</td>\n",
       "      <td>Single-Document QA</td>\n",
       "      <td>Financial</td>\n",
       "      <td>easy</td>\n",
       "      <td>short</td>\n",
       "      <td>According to the report, how to promote the co...</td>\n",
       "      <td>Through technology empowerment, change the way...</td>\n",
       "      <td>Establish new types of courts, such as intelle...</td>\n",
       "      <td>Improve the work ability of office staff and s...</td>\n",
       "      <td>Use advanced information systems to improve th...</td>\n",
       "      <td>D</td>\n",
       "      <td>Contents\\nPreface.\\n.............................</td>\n",
       "      <td>38133</td>\n",
       "      <td>True</td>\n",
       "      <td>A</td>\n",
       "      <td>3262</td>\n",
       "      <td>A</td>\n",
       "      <td>35327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66ebed525a08c7b9b35e1cb4</td>\n",
       "      <td>Single-Document QA</td>\n",
       "      <td>Academic</td>\n",
       "      <td>hard</td>\n",
       "      <td>short</td>\n",
       "      <td>When Miller tried to answer the question \"shou...</td>\n",
       "      <td>Each must read for himself or herself and test...</td>\n",
       "      <td>Readers must reach a high standrad to some deg...</td>\n",
       "      <td>It is the readers' obligation to get the \"trut...</td>\n",
       "      <td>The performative interpretation of language tr...</td>\n",
       "      <td>B</td>\n",
       "      <td>Chapter Five\\nJOSEPH CONRAD:\\nSHOULD WE READ\\n...</td>\n",
       "      <td>24007</td>\n",
       "      <td>True</td>\n",
       "      <td>B</td>\n",
       "      <td>2991</td>\n",
       "      <td>B</td>\n",
       "      <td>25610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>671b3cabbb02136c067d5252</td>\n",
       "      <td>Long-dialogue History Understanding</td>\n",
       "      <td>Agent history QA</td>\n",
       "      <td>hard</td>\n",
       "      <td>short</td>\n",
       "      <td>Which player got the least utility in the game?</td>\n",
       "      <td>player_1</td>\n",
       "      <td>player_3</td>\n",
       "      <td>player_5</td>\n",
       "      <td>player_7</td>\n",
       "      <td>B</td>\n",
       "      <td>{\\n  \"meta\": {\\n    \"name_exp\": \"gemini-1.0-pr...</td>\n",
       "      <td>43168</td>\n",
       "      <td>True</td>\n",
       "      <td>A</td>\n",
       "      <td>2549</td>\n",
       "      <td>B</td>\n",
       "      <td>47177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66ec0c4c821e116aacb1994a</td>\n",
       "      <td>Multi-Document QA</td>\n",
       "      <td>Academic</td>\n",
       "      <td>easy</td>\n",
       "      <td>medium</td>\n",
       "      <td>Which of the following statements is correct?</td>\n",
       "      <td>Both contractor data and data crawled from the...</td>\n",
       "      <td>All machine learning methods involved in the t...</td>\n",
       "      <td>Both voyager and VPT control Minecraft agents ...</td>\n",
       "      <td>VPT's modeling of action space is approximate ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Video PreTraining (VPT): Learning to Act by\\nW...</td>\n",
       "      <td>67185</td>\n",
       "      <td>True</td>\n",
       "      <td>A</td>\n",
       "      <td>2881</td>\n",
       "      <td>B</td>\n",
       "      <td>66821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66f920d8bb02136c067c4b81</td>\n",
       "      <td>Single-Document QA</td>\n",
       "      <td>Literary</td>\n",
       "      <td>hard</td>\n",
       "      <td>medium</td>\n",
       "      <td>What is mainly symbolized by the frequent chol...</td>\n",
       "      <td>Confusion of The Times</td>\n",
       "      <td>The impermanence of the character's fate</td>\n",
       "      <td>Love is dangerous and uncontrollable</td>\n",
       "      <td>Social indifference</td>\n",
       "      <td>C</td>\n",
       "      <td>Chapter 1\\nIT WAS INEVITABLE: the scent of bit...</td>\n",
       "      <td>85218</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>2855</td>\n",
       "      <td>D</td>\n",
       "      <td>95095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                               domain  \\\n",
       "0  66f36490821e116aacb2cc22                   Single-Document QA   \n",
       "1  66ebed525a08c7b9b35e1cb4                   Single-Document QA   \n",
       "2  671b3cabbb02136c067d5252  Long-dialogue History Understanding   \n",
       "3  66ec0c4c821e116aacb1994a                    Multi-Document QA   \n",
       "4  66f920d8bb02136c067c4b81                   Single-Document QA   \n",
       "\n",
       "         sub_domain difficulty  length  \\\n",
       "0         Financial       easy   short   \n",
       "1          Academic       hard   short   \n",
       "2  Agent history QA       hard   short   \n",
       "3          Academic       easy  medium   \n",
       "4          Literary       hard  medium   \n",
       "\n",
       "                                            question  \\\n",
       "0  According to the report, how to promote the co...   \n",
       "1  When Miller tried to answer the question \"shou...   \n",
       "2    Which player got the least utility in the game?   \n",
       "3      Which of the following statements is correct?   \n",
       "4  What is mainly symbolized by the frequent chol...   \n",
       "\n",
       "                                            choice_A  \\\n",
       "0  Through technology empowerment, change the way...   \n",
       "1  Each must read for himself or herself and test...   \n",
       "2                                           player_1   \n",
       "3  Both contractor data and data crawled from the...   \n",
       "4                             Confusion of The Times   \n",
       "\n",
       "                                            choice_B  \\\n",
       "0  Establish new types of courts, such as intelle...   \n",
       "1  Readers must reach a high standrad to some deg...   \n",
       "2                                           player_3   \n",
       "3  All machine learning methods involved in the t...   \n",
       "4           The impermanence of the character's fate   \n",
       "\n",
       "                                            choice_C  \\\n",
       "0  Improve the work ability of office staff and s...   \n",
       "1  It is the readers' obligation to get the \"trut...   \n",
       "2                                           player_5   \n",
       "3  Both voyager and VPT control Minecraft agents ...   \n",
       "4               Love is dangerous and uncontrollable   \n",
       "\n",
       "                                            choice_D answer  \\\n",
       "0  Use advanced information systems to improve th...      D   \n",
       "1  The performative interpretation of language tr...      B   \n",
       "2                                           player_7      B   \n",
       "3  VPT's modeling of action space is approximate ...      D   \n",
       "4                                Social indifference      C   \n",
       "\n",
       "                                             context  context_tokens  \\\n",
       "0  Contents\\nPreface.\\n.............................           38133   \n",
       "1  Chapter Five\\nJOSEPH CONRAD:\\nSHOULD WE READ\\n...           24007   \n",
       "2  {\\n  \"meta\": {\\n    \"name_exp\": \"gemini-1.0-pr...           43168   \n",
       "3  Video PreTraining (VPT): Learning to Act by\\nW...           67185   \n",
       "4  Chapter 1\\nIT WAS INEVITABLE: the scent of bit...           85218   \n",
       "\n",
       "   within_context_window llm_answer_simple  input_tokens_simple llm_answer_lc  \\\n",
       "0                   True                 A                 3262             A   \n",
       "1                   True                 B                 2991             B   \n",
       "2                   True                 A                 2549             B   \n",
       "3                   True                 A                 2881             B   \n",
       "4                   True                 C                 2855             D   \n",
       "\n",
       "   input_tokens_lc  \n",
       "0            35327  \n",
       "1            25610  \n",
       "2            47177  \n",
       "3            66821  \n",
       "4            95095  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639ec9dcc0e249d7b3560ee4b4c53418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple chunking\n",
    "generate_benchmarking_results(df_benchmark, \"simple\", df_context_simple, long_context=False)\n",
    "df_benchmark.to_csv(\"../data/longbench_results_checkpoint_1.csv\", index=False, sep=\"§\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25c68d48ab443b0b8fbf3fd96bbc79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sentence chunking\n",
    "generate_benchmarking_results(df_benchmark, \"sentence\", df_context_sentence, long_context=False)\n",
    "df_benchmark.to_csv(\"../data/longbench_results_checkpoint_2.csv\", index=False, sep=\"§\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fd90cb52ce4486b8c63ef6ad41fec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/151 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adaptive-semantic chunking\n",
    "df_benchmark_top = df_benchmark.iloc[:len(df_benchmark)//2] # Breaking df_benchmark into 2 halves to avoid overloading the model\n",
    "generate_benchmarking_results(df_benchmark_top, \"asc\", df_context_asc, long_context=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfcac2910e249279a4d8063ee9b57a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_benchmark_bottom = df_benchmark.iloc[len(df_benchmark)//2:]\n",
    "generate_benchmarking_results(df_benchmark_bottom, \"asc\", df_context_asc, long_context=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benchmark = pd.concat([df_benchmark_top, df_benchmark_bottom]) # Concatenating the 2 halves back together\n",
    "df_benchmark.to_csv(\"../data/longbench_results_checkpoint_3.csv\", index=False, sep=\"§\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b84dfe7dc8d4a6bba6ee94c2a52d300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Long context\n",
    "generate_benchmarking_results(df_benchmark, \"lc\", long_context=True)\n",
    "df_benchmark.to_csv(\"../data/longbench_results.csv\", index=False, sep=\"§\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
