{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "\n",
    "import logging\n",
    "import pandas as pd \n",
    "import csv\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from statistics import mean\n",
    "from utils.embeddings_utils import compute_text_embedding \n",
    "from utils.chunking_utils import adaptive_semantic_chunking, simple_chunking, sentence_chunking\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set to WARNING to mute INFO level logs\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('../logs/chunking.log')  # Remove StreamHandler to prevent console output\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)  # Also set logger level to WARNING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LongBench Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>domain</th>\n",
       "      <th>sub_domain</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>length</th>\n",
       "      <th>question</th>\n",
       "      <th>choice_A</th>\n",
       "      <th>choice_B</th>\n",
       "      <th>choice_C</th>\n",
       "      <th>choice_D</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>context_tokens</th>\n",
       "      <th>within_context_window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66f36490821e116aacb2cc22</td>\n",
       "      <td>Single-Document QA</td>\n",
       "      <td>Financial</td>\n",
       "      <td>easy</td>\n",
       "      <td>short</td>\n",
       "      <td>According to the report, how to promote the co...</td>\n",
       "      <td>Through technology empowerment, change the way...</td>\n",
       "      <td>Establish new types of courts, such as intelle...</td>\n",
       "      <td>Improve the work ability of office staff and s...</td>\n",
       "      <td>Use advanced information systems to improve th...</td>\n",
       "      <td>D</td>\n",
       "      <td>Contents\\nPreface.\\n.............................</td>\n",
       "      <td>38133</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66ebed525a08c7b9b35e1cb4</td>\n",
       "      <td>Single-Document QA</td>\n",
       "      <td>Academic</td>\n",
       "      <td>hard</td>\n",
       "      <td>short</td>\n",
       "      <td>When Miller tried to answer the question \"shou...</td>\n",
       "      <td>Each must read for himself or herself and test...</td>\n",
       "      <td>Readers must reach a high standrad to some deg...</td>\n",
       "      <td>It is the readers' obligation to get the \"trut...</td>\n",
       "      <td>The performative interpretation of language tr...</td>\n",
       "      <td>B</td>\n",
       "      <td>Chapter Five\\nJOSEPH CONRAD:\\nSHOULD WE READ\\n...</td>\n",
       "      <td>24007</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>671b3cabbb02136c067d5252</td>\n",
       "      <td>Long-dialogue History Understanding</td>\n",
       "      <td>Agent history QA</td>\n",
       "      <td>hard</td>\n",
       "      <td>short</td>\n",
       "      <td>Which player got the least utility in the game?</td>\n",
       "      <td>player_1</td>\n",
       "      <td>player_3</td>\n",
       "      <td>player_5</td>\n",
       "      <td>player_7</td>\n",
       "      <td>B</td>\n",
       "      <td>{\\n  \"meta\": {\\n    \"name_exp\": \"gemini-1.0-pr...</td>\n",
       "      <td>43168</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66ec0c4c821e116aacb1994a</td>\n",
       "      <td>Multi-Document QA</td>\n",
       "      <td>Academic</td>\n",
       "      <td>easy</td>\n",
       "      <td>medium</td>\n",
       "      <td>Which of the following statements is correct?</td>\n",
       "      <td>Both contractor data and data crawled from the...</td>\n",
       "      <td>All machine learning methods involved in the t...</td>\n",
       "      <td>Both voyager and VPT control Minecraft agents ...</td>\n",
       "      <td>VPT's modeling of action space is approximate ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Video PreTraining (VPT): Learning to Act by\\nW...</td>\n",
       "      <td>67185</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66f920d8bb02136c067c4b81</td>\n",
       "      <td>Single-Document QA</td>\n",
       "      <td>Literary</td>\n",
       "      <td>hard</td>\n",
       "      <td>medium</td>\n",
       "      <td>What is mainly symbolized by the frequent chol...</td>\n",
       "      <td>Confusion of The Times</td>\n",
       "      <td>The impermanence of the character's fate</td>\n",
       "      <td>Love is dangerous and uncontrollable</td>\n",
       "      <td>Social indifference</td>\n",
       "      <td>C</td>\n",
       "      <td>Chapter 1\\nIT WAS INEVITABLE: the scent of bit...</td>\n",
       "      <td>85218</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                               domain  \\\n",
       "0  66f36490821e116aacb2cc22                   Single-Document QA   \n",
       "1  66ebed525a08c7b9b35e1cb4                   Single-Document QA   \n",
       "2  671b3cabbb02136c067d5252  Long-dialogue History Understanding   \n",
       "3  66ec0c4c821e116aacb1994a                    Multi-Document QA   \n",
       "4  66f920d8bb02136c067c4b81                   Single-Document QA   \n",
       "\n",
       "         sub_domain difficulty  length  \\\n",
       "0         Financial       easy   short   \n",
       "1          Academic       hard   short   \n",
       "2  Agent history QA       hard   short   \n",
       "3          Academic       easy  medium   \n",
       "4          Literary       hard  medium   \n",
       "\n",
       "                                            question  \\\n",
       "0  According to the report, how to promote the co...   \n",
       "1  When Miller tried to answer the question \"shou...   \n",
       "2    Which player got the least utility in the game?   \n",
       "3      Which of the following statements is correct?   \n",
       "4  What is mainly symbolized by the frequent chol...   \n",
       "\n",
       "                                            choice_A  \\\n",
       "0  Through technology empowerment, change the way...   \n",
       "1  Each must read for himself or herself and test...   \n",
       "2                                           player_1   \n",
       "3  Both contractor data and data crawled from the...   \n",
       "4                             Confusion of The Times   \n",
       "\n",
       "                                            choice_B  \\\n",
       "0  Establish new types of courts, such as intelle...   \n",
       "1  Readers must reach a high standrad to some deg...   \n",
       "2                                           player_3   \n",
       "3  All machine learning methods involved in the t...   \n",
       "4           The impermanence of the character's fate   \n",
       "\n",
       "                                            choice_C  \\\n",
       "0  Improve the work ability of office staff and s...   \n",
       "1  It is the readers' obligation to get the \"trut...   \n",
       "2                                           player_5   \n",
       "3  Both voyager and VPT control Minecraft agents ...   \n",
       "4               Love is dangerous and uncontrollable   \n",
       "\n",
       "                                            choice_D answer  \\\n",
       "0  Use advanced information systems to improve th...      D   \n",
       "1  The performative interpretation of language tr...      B   \n",
       "2                                           player_7      B   \n",
       "3  VPT's modeling of action space is approximate ...      D   \n",
       "4                                Social indifference      C   \n",
       "\n",
       "                                             context  context_tokens  \\\n",
       "0  Contents\\nPreface.\\n.............................           38133   \n",
       "1  Chapter Five\\nJOSEPH CONRAD:\\nSHOULD WE READ\\n...           24007   \n",
       "2  {\\n  \"meta\": {\\n    \"name_exp\": \"gemini-1.0-pr...           43168   \n",
       "3  Video PreTraining (VPT): Learning to Act by\\nW...           67185   \n",
       "4  Chapter 1\\nIT WAS INEVITABLE: the scent of bit...           85218   \n",
       "\n",
       "   within_context_window  \n",
       "0                   True  \n",
       "1                   True  \n",
       "2                   True  \n",
       "3                   True  \n",
       "4                   True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_longbench_filtered = pd.read_csv('../data/longbench_filtered.csv', delimiter=\"§\", engine='python')\n",
    "df_longbench_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_longbench_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Adaptive Semantic Chunking for filtered LongBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 303/303 [7:48:47<00:00, 92.83s/it]   \n"
     ]
    }
   ],
   "source": [
    "df_longbench_context_chunked_asc = pd.DataFrame(columns=[\"_id\", \"chunk_id\", \"chunk_text\", \"embeddings\"]) \n",
    "\n",
    "for _, row in tqdm(df_longbench_filtered.iterrows(), total=len(df_longbench_filtered)):\n",
    "    logger.info(f\"Processing row {row['_id']} #########################################################\")\n",
    "    id = row[\"_id\"]\n",
    "    context = row[\"context\"]\n",
    "    chunk_list, embeddings_list, cosine_similarity_list = adaptive_semantic_chunking(context, similarity_threshold=0.75)\n",
    "    logger.info(f\"Mean cosine similarity: {mean(cosine_similarity_list)}\")\n",
    "    for i in range(len(chunk_list)):\n",
    "        chunk_text = chunk_list[i]\n",
    "        chunk_embedding = embeddings_list[i]\n",
    "        df_longbench_context_chunked_asc = pd.concat([df_longbench_context_chunked_asc, pd.DataFrame([{\"_id\": id, \"chunk_id\": i, \"chunk_text\": chunk_text, \"embeddings\": chunk_embedding}])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66f36490821e116aacb2cc22</td>\n",
       "      <td>0</td>\n",
       "      <td>Contents\\nPreface.\\n.............................</td>\n",
       "      <td>[[-0.0290374755859375, -0.0050048828125, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66f36490821e116aacb2cc22</td>\n",
       "      <td>1</td>\n",
       "      <td>Advancing the Construction of Intelligent Cour...</td>\n",
       "      <td>[[-0.0261077880859375, 0.0311126708984375, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66f36490821e116aacb2cc22</td>\n",
       "      <td>2</td>\n",
       "      <td>67\\n-\\n-\\nJudicial Reform of Chinese Courts（20...</td>\n",
       "      <td>[[-0.009765625, 0.031280517578125, -0.04086303...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66f36490821e116aacb2cc22</td>\n",
       "      <td>3</td>\n",
       "      <td>The said three Programs served as the basis of...</td>\n",
       "      <td>[[0.00789642333984375, 0.01081085205078125, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66f36490821e116aacb2cc22</td>\n",
       "      <td>4</td>\n",
       "      <td>In consideration that the improvement of class...</td>\n",
       "      <td>[[-0.045562744140625, 0.043731689453125, -0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id chunk_id  \\\n",
       "0  66f36490821e116aacb2cc22        0   \n",
       "1  66f36490821e116aacb2cc22        1   \n",
       "2  66f36490821e116aacb2cc22        2   \n",
       "3  66f36490821e116aacb2cc22        3   \n",
       "4  66f36490821e116aacb2cc22        4   \n",
       "\n",
       "                                          chunk_text  \\\n",
       "0  Contents\\nPreface.\\n.............................   \n",
       "1  Advancing the Construction of Intelligent Cour...   \n",
       "2  67\\n-\\n-\\nJudicial Reform of Chinese Courts（20...   \n",
       "3  The said three Programs served as the basis of...   \n",
       "4  In consideration that the improvement of class...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [[-0.0290374755859375, -0.0050048828125, -0.03...  \n",
       "1  [[-0.0261077880859375, 0.0311126708984375, 0.0...  \n",
       "2  [[-0.009765625, 0.031280517578125, -0.04086303...  \n",
       "3  [[0.00789642333984375, 0.01081085205078125, -0...  \n",
       "4  [[-0.045562744140625, 0.043731689453125, -0.01...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_longbench_context_chunked_asc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_longbench_context_chunked_asc.to_csv(\"../data/longbench_context_chunked_asc.csv\", index=False, sep=\"§\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Simple Chunking for filtered LongBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_simple_chunking(df, chunk_size=256, chunk_overlap=20):\n",
    "    \"\"\"\n",
    "    Simple fixed-size chunking with optional overlap for LongBench dataset.\n",
    "\n",
    "    Parameters:\n",
    "    df: Input DataFrame containing '_id' and 'context'\n",
    "    chunk_size: Number of tokens per chunk\n",
    "    overlap: Token overlap between consecutive chunks\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Chunked dataset with columns [_id, chunk_id, chunk_text, embeddings]\n",
    "    \"\"\"\n",
    "\n",
    "    chunked_df = pd.DataFrame(columns=[\"_id\", \"chunk_id\", \"chunk_text\", \"embeddings\"])\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        context = row[\"context\"]\n",
    "        chunks = simple_chunking(text=context, chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        embeddings = [compute_text_embedding(chunk) for chunk in chunks]\n",
    "\n",
    "        chunked_df = pd.concat([chunked_df, pd.DataFrame({\n",
    "            \"_id\": [row[\"_id\"]] * len(chunks),\n",
    "            \"chunk_id\": range(len(chunks)),\n",
    "            \"chunk_text\": chunks,\n",
    "            \"embeddings\": embeddings\n",
    "        })], ignore_index=True)\n",
    "\n",
    "    return chunked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:53<00:00, 46.67s/it]\n"
     ]
    }
   ],
   "source": [
    "df_longbench_context_chunked_simple = apply_simple_chunking(\n",
    "    df=df_longbench_filtered,  \n",
    "    chunk_size=512,            \n",
    "    chunk_overlap=64              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_longbench_context_chunked_simple.to_csv('../data/longbench_context_chunked_simple.csv', sep=\"§\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Sentence Chunking for filtered LongBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def sentence_chunking(text):\n",
    "    sentence_endings = re.compile(r'(?<=[.!?]) +')\n",
    "    sentences = sentence_endings.split(text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/303 [02:46<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m chunked_df\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# 应用句子分块\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m df_longbench_context_chunked_sentence = apply_sentence_chunking(df_longbench_filtered)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mapply_sentence_chunking\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# 假设我们有一个函数sentence_chunking来进行句子分块\u001b[39;00m\n\u001b[32m     16\u001b[39m     chunks = sentence_chunking(text=context)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     embeddings = [compute_text_embedding(chunk) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[32m     19\u001b[39m     chunked_df = pd.concat([chunked_df, pd.DataFrame({\n\u001b[32m     20\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m_id\u001b[39m\u001b[33m\"\u001b[39m: [row[\u001b[33m\"\u001b[39m\u001b[33m_id\u001b[39m\u001b[33m\"\u001b[39m]] * \u001b[38;5;28mlen\u001b[39m(chunks),\n\u001b[32m     21\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mchunk_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(chunks)),\n\u001b[32m     22\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mchunk_text\u001b[39m\u001b[33m\"\u001b[39m: chunks,\n\u001b[32m     23\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m: embeddings\n\u001b[32m     24\u001b[39m     })], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m chunked_df\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# 假设我们有一个函数sentence_chunking来进行句子分块\u001b[39;00m\n\u001b[32m     16\u001b[39m     chunks = sentence_chunking(text=context)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     embeddings = [compute_text_embedding(chunk) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[32m     19\u001b[39m     chunked_df = pd.concat([chunked_df, pd.DataFrame({\n\u001b[32m     20\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m_id\u001b[39m\u001b[33m\"\u001b[39m: [row[\u001b[33m\"\u001b[39m\u001b[33m_id\u001b[39m\u001b[33m\"\u001b[39m]] * \u001b[38;5;28mlen\u001b[39m(chunks),\n\u001b[32m     21\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mchunk_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(chunks)),\n\u001b[32m     22\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mchunk_text\u001b[39m\u001b[33m\"\u001b[39m: chunks,\n\u001b[32m     23\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m: embeddings\n\u001b[32m     24\u001b[39m     })], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m chunked_df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/ST311_group_project/notebooks/../utils/embeddings_utils.py:12\u001b[39m, in \u001b[36mcompute_text_embedding\u001b[39m\u001b[34m(text, embed_model)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_text_embedding\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m, embed_model: \u001b[38;5;28mstr\u001b[39m = embed_model_instance): \n\u001b[32m      9\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m    This function takes a text and returns an embedding for the text. \u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [embed_model.encode(text)[\u001b[33m\"\u001b[39m\u001b[33mdense_vecs\u001b[39m\u001b[33m\"\u001b[39m].tolist()]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/FlagEmbedding/inference/embedder/encoder_only/m3.py:295\u001b[39m, in \u001b[36mM3Embedder.encode\u001b[39m\u001b[34m(self, sentences, batch_size, max_length, return_dense, return_sparse, return_colbert_vecs, **kwargs)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_sparse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: return_sparse = \u001b[38;5;28mself\u001b[39m.return_sparse\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_colbert_vecs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: return_colbert_vecs = \u001b[38;5;28mself\u001b[39m.return_colbert_vecs\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().encode(\n\u001b[32m    296\u001b[39m     sentences,\n\u001b[32m    297\u001b[39m     batch_size=batch_size,\n\u001b[32m    298\u001b[39m     max_length=max_length,\n\u001b[32m    299\u001b[39m     return_dense=return_dense,\n\u001b[32m    300\u001b[39m     return_sparse=return_sparse,\n\u001b[32m    301\u001b[39m     return_colbert_vecs=return_colbert_vecs,\n\u001b[32m    302\u001b[39m     **kwargs\n\u001b[32m    303\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/FlagEmbedding/abc/inference/AbsEmbedder.py:264\u001b[39m, in \u001b[36mAbsEmbedder.encode\u001b[39m\u001b[34m(self, sentences, batch_size, max_length, convert_to_numpy, instruction, instruction_format, **kwargs)\u001b[39m\n\u001b[32m    260\u001b[39m         sentences = [\u001b[38;5;28mself\u001b[39m.get_detailed_instruct(instruction_format, instruction, sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m\n\u001b[32m    261\u001b[39m                      sentences]\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sentences, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.target_devices) == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encode_single_device(\n\u001b[32m    265\u001b[39m         sentences,\n\u001b[32m    266\u001b[39m         batch_size=batch_size,\n\u001b[32m    267\u001b[39m         max_length=max_length,\n\u001b[32m    268\u001b[39m         convert_to_numpy=convert_to_numpy,\n\u001b[32m    269\u001b[39m         device=\u001b[38;5;28mself\u001b[39m.target_devices[\u001b[32m0\u001b[39m],\n\u001b[32m    270\u001b[39m         **kwargs\n\u001b[32m    271\u001b[39m     )\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28mself\u001b[39m.pool = \u001b[38;5;28mself\u001b[39m.start_multi_process_pool(AbsEmbedder._encode_multi_process_worker)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/FlagEmbedding/inference/embedder/encoder_only/m3.py:423\u001b[39m, in \u001b[36mM3Embedder.encode_single_device\u001b[39m\u001b[34m(self, sentences, batch_size, max_length, return_dense, return_sparse, return_colbert_vecs, device, **kwargs)\u001b[39m\n\u001b[32m    416\u001b[39m inputs_batch = all_inputs_sorted[start_index:start_index + batch_size]\n\u001b[32m    417\u001b[39m inputs_batch = \u001b[38;5;28mself\u001b[39m.tokenizer.pad(\n\u001b[32m    418\u001b[39m     inputs_batch,\n\u001b[32m    419\u001b[39m     padding=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    420\u001b[39m     return_tensors=\u001b[33m'\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    421\u001b[39m     **kwargs\n\u001b[32m    422\u001b[39m ).to(device)\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m outputs = \u001b[38;5;28mself\u001b[39m.model(\n\u001b[32m    424\u001b[39m     inputs_batch,\n\u001b[32m    425\u001b[39m     return_dense=return_dense,\n\u001b[32m    426\u001b[39m     return_sparse=return_sparse,\n\u001b[32m    427\u001b[39m     return_colbert_vecs=return_colbert_vecs\n\u001b[32m    428\u001b[39m )\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dense:\n\u001b[32m    431\u001b[39m     all_dense_embeddings.append(outputs[\u001b[33m'\u001b[39m\u001b[33mdense_vecs\u001b[39m\u001b[33m'\u001b[39m].cpu().numpy())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/FlagEmbedding/finetune/embedder/encoder_only/m3/modeling.py:524\u001b[39m, in \u001b[36mEncoderOnlyEmbedderM3ModelForInference.forward\u001b[39m\u001b[34m(self, text_input, return_dense, return_sparse, return_colbert_vecs, return_sparse_embedding)\u001b[39m\n\u001b[32m    509\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Encode the text input using the selected way.\u001b[39;00m\n\u001b[32m    510\u001b[39m \n\u001b[32m    511\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    520\u001b[39m \u001b[33;03m    dict: A dictionary containing the three types of embeddings.\u001b[39;00m\n\u001b[32m    521\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m return_dense \u001b[38;5;129;01mor\u001b[39;00m return_sparse \u001b[38;5;129;01mor\u001b[39;00m return_colbert_vecs, \u001b[33m'\u001b[39m\u001b[33mMust choose one or more from `return_colbert_vecs`, `return_sparse`, `return_dense` to set `True`!\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m last_hidden_state = \u001b[38;5;28mself\u001b[39m.model(**text_input, return_dict=\u001b[38;5;28;01mTrue\u001b[39;00m).last_hidden_state\n\u001b[32m    526\u001b[39m output = {}\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dense:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:979\u001b[39m, in \u001b[36mXLMRobertaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    972\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    973\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    974\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    975\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    976\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    977\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m encoder_outputs = \u001b[38;5;28mself\u001b[39m.encoder(\n\u001b[32m    980\u001b[39m     embedding_output,\n\u001b[32m    981\u001b[39m     attention_mask=extended_attention_mask,\n\u001b[32m    982\u001b[39m     head_mask=head_mask,\n\u001b[32m    983\u001b[39m     encoder_hidden_states=encoder_hidden_states,\n\u001b[32m    984\u001b[39m     encoder_attention_mask=encoder_extended_attention_mask,\n\u001b[32m    985\u001b[39m     past_key_values=past_key_values,\n\u001b[32m    986\u001b[39m     use_cache=use_cache,\n\u001b[32m    987\u001b[39m     output_attentions=output_attentions,\n\u001b[32m    988\u001b[39m     output_hidden_states=output_hidden_states,\n\u001b[32m    989\u001b[39m     return_dict=return_dict,\n\u001b[32m    990\u001b[39m )\n\u001b[32m    991\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    992\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:632\u001b[39m, in \u001b[36mXLMRobertaEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    621\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    622\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    623\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    629\u001b[39m         output_attentions,\n\u001b[32m    630\u001b[39m     )\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m     layer_outputs = layer_module(\n\u001b[32m    633\u001b[39m         hidden_states,\n\u001b[32m    634\u001b[39m         attention_mask,\n\u001b[32m    635\u001b[39m         layer_head_mask,\n\u001b[32m    636\u001b[39m         encoder_hidden_states,\n\u001b[32m    637\u001b[39m         encoder_attention_mask,\n\u001b[32m    638\u001b[39m         past_key_value,\n\u001b[32m    639\u001b[39m         output_attentions,\n\u001b[32m    640\u001b[39m     )\n\u001b[32m    642\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:563\u001b[39m, in \u001b[36mXLMRobertaLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    560\u001b[39m     cross_attn_present_key_value = cross_attention_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    561\u001b[39m     present_key_value = present_key_value + cross_attn_present_key_value\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m layer_output = apply_chunking_to_forward(\n\u001b[32m    564\u001b[39m     \u001b[38;5;28mself\u001b[39m.feed_forward_chunk, \u001b[38;5;28mself\u001b[39m.chunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m.seq_len_dim, attention_output\n\u001b[32m    565\u001b[39m )\n\u001b[32m    566\u001b[39m outputs = (layer_output,) + outputs\n\u001b[32m    568\u001b[39m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/transformers/pytorch_utils.py:253\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    250\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(*input_tensors)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:575\u001b[39m, in \u001b[36mXLMRobertaLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     intermediate_output = \u001b[38;5;28mself\u001b[39m.intermediate(attention_output)\n\u001b[32m    576\u001b[39m     layer_output = \u001b[38;5;28mself\u001b[39m.output(intermediate_output, attention_output)\n\u001b[32m    577\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:473\u001b[39m, in \u001b[36mXLMRobertaIntermediate.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.dense(hidden_states)\n\u001b[32m    474\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.intermediate_act_fn(hidden_states)\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/st311/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.linear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m.weight, \u001b[38;5;28mself\u001b[39m.bias)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def apply_sentence_chunking(df):\n",
    "    \"\"\"\n",
    "    Sentence-based chunking for LongBench dataset.\n",
    "\n",
    "    Parameters:\n",
    "    df: Input DataFrame containing '_id' and 'context'\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Chunked dataset with columns [_id, chunk_id, chunk_text, embeddings]\n",
    "    \"\"\"\n",
    "    chunked_df = pd.DataFrame(columns=[\"_id\", \"chunk_id\", \"chunk_text\", \"embeddings\"])\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        context = row[\"context\"]\n",
    "        chunks = sentence_chunking(text=context)\n",
    "        embeddings = [compute_text_embedding(chunk) for chunk in chunks]\n",
    "\n",
    "        chunked_df = pd.concat([chunked_df, pd.DataFrame({\n",
    "            \"_id\": [row[\"_id\"]] * len(chunks),\n",
    "            \"chunk_id\": range(len(chunks)),\n",
    "            \"chunk_text\": chunks,\n",
    "            \"embeddings\": embeddings\n",
    "        })], ignore_index=True)\n",
    "\n",
    "    return chunked_df\n",
    "\n",
    "df_longbench_context_chunked_sentence = apply_sentence_chunking(df_longbench_filtered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
